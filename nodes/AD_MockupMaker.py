import PIL.Image as Image
import PIL.ImageDraw as ImageDraw
import PIL.ImageFilter as ImageFilter
import numpy as np
import torch
import torchvision.transforms as t
import math

class AD_MockupMaker:
    """Create mockup with scaled image overlay and blurred background."""
    
    def __init__(self):
        pass

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "create_mockup"
    CATEGORY = "ðŸŒ» Addoor/image"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "overlay_image": ("IMAGE",),
                "background_image": ("IMAGE",),
                "target_width": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 4096,
                    "step": 8,
                    "description": "Target width for the overlay"
                }),
                "target_height": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 4096,
                    "step": 8,
                    "description": "Target height for the overlay"
                }),
                "corner_radius": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 500,
                    "step": 1,
                    "description": "Radius for rounded corners"
                }),
                "offset_x": ("INT", {
                    "default": 0,
                    "min": -1000,
                    "max": 1000,
                    "step": 1,
                    "description": "Horizontal offset in pixels"
                }),
                "offset_y": ("INT", {
                    "default": 0,
                    "min": -1000,
                    "max": 1000,
                    "step": 1,
                    "description": "Vertical offset in pixels"
                }),
                "blur_radius": ("FLOAT", {
                    "default": 10.0,
                    "min": 0.0,
                    "max": 50.0,
                    "step": 0.5,
                    "description": "Gaussian blur radius for background"
                }),
                "SSAA": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "description": "Super Sampling Anti-Aliasing factor"
                }),
                "method": (["lanczos", "bicubic", "bilinear"], {
                    "default": "lanczos",
                    "description": "Resampling method"
                }),
            },
            "optional": {
                "watermark": ("IMAGE",),
                "mask": ("MASK",),
            }
        }

    def add_corners(self, image, radius, ssaa=1):
        """Add rounded corners to an image."""
        if radius <= 0:
            return image
            
        # è°ƒæ•´åœ†è§’åŠå¾„ä»¥é€‚åº”SSAA
        working_radius = radius * ssaa
        
        # åˆ›å»ºåœ†è§’è’™ç‰ˆ
        mask = Image.new('L', image.size, 0)
        draw = ImageDraw.Draw(mask)
        draw.rounded_rectangle(
            [(0, 0), (image.width, image.height)],
            radius=working_radius,
            fill=255
        )
        
        # ç¡®ä¿å›¾åƒä¸ºRGBAæ¨¡å¼
        output = image.convert('RGBA')
        output.putalpha(mask)
        
        return output

    def fit_and_crop(self, image, target_width, target_height, method, ssaa=1):
        """Fit image to target size maintaining aspect ratio and crop if necessary."""
        # è®¡ç®—SSAAå°ºå¯¸
        ssaa_width = target_width * ssaa
        ssaa_height = target_height * ssaa
        
        # è®¡ç®—ç›®æ ‡å°ºå¯¸ä¸ŽåŽŸå§‹å°ºå¯¸çš„æ¯”ä¾‹
        width_ratio = ssaa_width / image.width
        height_ratio = ssaa_height / image.height
        
        # ä½¿ç”¨è¾ƒå¤§çš„æ¯”ä¾‹æ¥ç¡®ä¿å¡«å……ç›®æ ‡åŒºåŸŸ
        scale = max(width_ratio, height_ratio)
        
        # ç¼©æ”¾å›¾åƒ
        new_width = int(image.width * scale)
        new_height = int(image.height * scale)
        resized = image.resize((new_width, new_height), method)
        
        # è®¡ç®—è£åˆ‡åŒºåŸŸ
        left = (new_width - ssaa_width) // 2
        top = (new_height - ssaa_height) // 2
        right = left + ssaa_width
        bottom = top + ssaa_height
        
        # è£åˆ‡åˆ°ç›®æ ‡å°ºå¯¸
        cropped = resized.crop((left, top, right, bottom))
        return cropped

    def create_mockup(
        self,
        overlay_image,
        background_image,
        target_width: int,
        target_height: int,
        corner_radius: int,
        offset_x: int,
        offset_y: int,
        blur_radius: float,
        SSAA: int,
        method: str,
        watermark = None,
        mask = None,
    ):
        try:
            print("Starting mockup creation...")
            
            # 1. åˆå§‹åŒ–å›¾åƒ
            overlay = tensor_to_image(overlay_image[0])
            background = tensor_to_image(background_image[0])
            
            print(f"Original sizes - Overlay: {overlay.size}, Background: {background.size}")
            
            # 2. è°ƒæ•´èƒŒæ™¯å›¾å°ºå¯¸å¹¶æ¨¡ç³Š
            background = background.resize(
                (overlay.width, overlay.height),
                get_sampler_by_name(method)
            )
            
            if blur_radius > 0:
                background = background.filter(ImageFilter.GaussianBlur(radius=blur_radius))
            
            # 3. ç¼©æ”¾å¹¶è£åˆ‡ä¸»å›¾
            scaled_overlay = self.fit_and_crop(
                overlay,
                target_width,
                target_height,
                get_sampler_by_name(method),
                SSAA
            )
            
            print(f"After scaling - Overlay: {scaled_overlay.size}")
            
            # 4. è½¬æ¢ä¸ºRGBAæ¨¡å¼
            scaled_overlay = scaled_overlay.convert('RGBA')
            
            # 5. æ·»åŠ åœ†è§’
            if corner_radius > 0:
                scaled_overlay = self.add_corners(scaled_overlay, corner_radius, SSAA)
            
            # 6. å¦‚æžœä½¿ç”¨äº†SSAAï¼Œç¼©å°åˆ°ç›®æ ‡å°ºå¯¸
            if SSAA > 1:
                scaled_overlay = scaled_overlay.resize(
                    (target_width, target_height),
                    get_sampler_by_name(method)
                )
            
            # 7. åº”ç”¨maské®ç½©ï¼ˆå¦‚æžœæœ‰ï¼‰
            if mask is not None:
                try:
                    # å¤„ç†maskç»´åº¦
                    if len(mask.shape) == 3:
                        mask = mask.squeeze(0)
                    if len(mask.shape) == 3:
                        mask = mask.squeeze(-1)
                    
                    # è½¬æ¢maskä¸ºPIL Image
                    mask_array = mask.cpu().numpy()
                    mask_array = (mask_array * 255).astype(np.uint8)
                    mask_img = Image.fromarray(mask_array, mode='L')
                    
                    # é¦–å…ˆå°†maskè°ƒæ•´åˆ°åŽŸå›¾å°ºå¯¸
                    mask_img = mask_img.resize(
                        (background.width, background.height),
                        get_sampler_by_name(method)
                    )
                    
                    # ç„¶åŽè£åˆ‡å‡ºéœ€è¦çš„éƒ¨åˆ†ï¼ˆä¸Žscaled_overlayç›¸åŒå¤§å°çš„åŒºåŸŸï¼‰
                    crop_x = (background.width - scaled_overlay.width) // 2 + offset_x
                    crop_y = (background.height - scaled_overlay.height) // 2 + offset_y
                    mask_img = mask_img.crop((
                        crop_x,
                        crop_y,
                        crop_x + scaled_overlay.width,
                        crop_y + scaled_overlay.height
                    ))
                    
                    print(f"Mask size: {mask_img.size}, Overlay size: {scaled_overlay.size}")
                    
                    # èŽ·å–å½“å‰alphaé€šé“
                    r, g, b, a = scaled_overlay.split()
                    
                    # åˆå¹¶maskå’ŒçŽ°æœ‰alphaé€šé“
                    if corner_radius > 0:
                        # å¦‚æžœæœ‰åœ†è§’ï¼Œå°†maskä¸ŽçŽ°æœ‰alphaé€šé“ç›¸ä¹˜
                        combined_alpha = Image.fromarray(
                            (np.array(mask_img) * np.array(a) / 255).astype(np.uint8)
                        )
                    else:
                        # å¦‚æžœæ²¡æœ‰åœ†è§’ï¼Œç›´æŽ¥ä½¿ç”¨mask
                        combined_alpha = mask_img
                    
                    # æ›´æ–°alphaé€šé“
                    scaled_overlay.putalpha(combined_alpha)
                    print("Mask applied successfully")
                    
                except Exception as e:
                    print(f"Error processing mask: {str(e)}")
                    import traceback
                    traceback.print_exc()
            
            print(f"Final overlay size: {scaled_overlay.size}")
            
            # 8. å‡†å¤‡æœ€ç»ˆåˆæˆ
            result = background.copy()
            result = result.convert('RGBA')
            
            # 9. è®¡ç®—ç²˜è´´ä½ç½®å¹¶åˆæˆä¸»å›¾
            paste_x = (background.width - scaled_overlay.width) // 2 + offset_x
            paste_y = (background.height - scaled_overlay.height) // 2 + offset_y
            
            temp = Image.new('RGBA', result.size, (0, 0, 0, 0))
            temp.paste(scaled_overlay, (paste_x, paste_y), scaled_overlay)
            result = Image.alpha_composite(result, temp)
            
            # 10. æ·»åŠ æ°´å°ï¼ˆå¦‚æžœæœ‰ï¼‰
            if watermark is not None:
                try:
                    watermark_img = tensor_to_image(watermark[0])
                    watermark_img = watermark_img.convert('RGBA')
                    watermark_img = watermark_img.resize(
                        (background.width, background.height),
                        get_sampler_by_name(method)
                    )
                    result = Image.alpha_composite(result, watermark_img)
                except Exception as e:
                    print(f"Error processing watermark: {str(e)}")
            
            # 11. æœ€ç»ˆè½¬æ¢
            result = result.convert('RGB')
            tensor = image_to_tensor(result)
            tensor = tensor.unsqueeze(0)
            tensor = tensor.permute(0, 2, 3, 1)
            
            print("Mockup creation completed successfully")
            return (tensor,)
            
        except Exception as e:
            print(f"Error in create_mockup: {str(e)}")
            import traceback
            traceback.print_exc()
            return (overlay_image,)

def get_sampler_by_name(method: str) -> int:
    """Get PIL resampling method by name."""
    samplers = {
        "lanczos": Image.LANCZOS,
        "bicubic": Image.BICUBIC,
        "bilinear": Image.BILINEAR,
    }
    return samplers.get(method, Image.LANCZOS)

def tensor_to_image(tensor):
    """Convert tensor to PIL Image."""
    if len(tensor.shape) == 4:
        tensor = tensor.squeeze(0)
    return t.ToPILImage()(tensor.permute(2, 0, 1))

def image_to_tensor(image):
    """Convert PIL Image to tensor."""
    tensor = t.ToTensor()(image)
    return tensor

NODE_CLASS_MAPPINGS = {
    "AD_mockup-maker": AD_MockupMaker,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AD_mockup-maker": "AD Mockup Maker",
} 