"""
@name: "ComfyUI ImageCaptioner"
@version: "1.1.1"
@author: "ComfyNodePRs"
@description: "Image captioning and text chat toolkit for ComfyUI using Qwen models"
"""

import os
import json
import base64
import numpy as np
import torch
from PIL import Image
from io import BytesIO

try:
    from openai import OpenAI
except ImportError:
    print("è¯·å…ˆå®‰è£… openai: pip install openai")

# æ·»åŠ å¸¸é‡é…ç½®
DEFAULT_MAX_TOKENS = 512
MAX_TOKENS_LIMIT = 1024

class ImageCaptioner:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "user_prompt": ("STRING", {"default": "è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ", "multiline": True}),
                "system_prompt": ("STRING", {
                    "default": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI åŠ©æ‰‹ï¼Œæ“…é•¿å›¾åƒåˆ†æå’Œæ–‡å­—å¯¹è¯ã€‚åœ¨æè¿°å›¾ç‰‡æ—¶ï¼Œè¯·æ³¨æ„ç»†èŠ‚å¹¶ä½¿ç”¨ä¸“ä¸šçš„æœ¯è¯­ï¼›åœ¨å¯¹è¯æ—¶ï¼Œä¿æŒå‹å¥½å’Œä¸“ä¸šã€‚",
                    "multiline": True
                }),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "dashscope_api_key": ("STRING", {"default": "", "multiline": False}),
            },
            "optional": {
                "image": ("IMAGE",),
                "max_tokens": ("INT", {
                    "default": DEFAULT_MAX_TOKENS,
                    "min": 1, 
                    "max": MAX_TOKENS_LIMIT,
                    "step": 1,
                    "display": "number"
                })
            }
        }
    
    RETURN_TYPES = ("STRING",)
    FUNCTION = "generate_response"
    CATEGORY = "ğŸŒ» Addoor/API"

    def post_process_prompt(self, response_data):
        try:
            if not response_data or not isinstance(response_data, dict):
                return "Error: Invalid response format"
            
            # ä»è¿”å›çš„JSONä¸­æå–æ–‡æœ¬å†…å®¹
            if 'choices' in response_data and len(response_data['choices']) > 0:
                message = response_data['choices'][0].get('message', {})
                content = message.get('content', '')
                if content:
                    return content.strip()
            
            return "Error: No valid content in response"
            
        except Exception as e:
            return f"Error processing response: {str(e)}"

    def create_text_completion(self, client, system_prompt, user_prompt, max_tokens=None):
        """çº¯æ–‡æœ¬å¯¹è¯è¯·æ±‚"""
        # ç¡®ä¿ max_tokens ä¸è¶…è¿‡é™åˆ¶
        max_tokens = min(max_tokens or DEFAULT_MAX_TOKENS, MAX_TOKENS_LIMIT)
        
        params = {
            "model": "qwen-plus",
            "messages": [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            "max_tokens": max_tokens
        }
            
        completion = client.chat.completions.create(**params)
        return completion

    def create_image_completion(self, client, system_prompt, user_prompt, image_url, max_tokens=None):
        """å›¾åƒæè¿°è¯·æ±‚"""
        # ç¡®ä¿ max_tokens ä¸è¶…è¿‡é™åˆ¶
        max_tokens = min(max_tokens or DEFAULT_MAX_TOKENS, MAX_TOKENS_LIMIT)
        
        params = {
            "model": "qwen-vl-plus",
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": user_prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }],
            "max_tokens": max_tokens
        }
            
        completion = client.chat.completions.create(**params)
        return completion

    def generate_response(self, user_prompt, system_prompt, seed, dashscope_api_key, image=None, max_tokens=None):
        # seed å‚æ•°ä»…ç”¨äº ComfyUI èŠ‚ç‚¹ç³»ç»Ÿï¼Œä¸ä¼ é€’ç»™ API
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(
                api_key=dashscope_api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
            
            # åˆ¤æ–­æ˜¯å¦æœ‰å›¾ç‰‡è¾“å…¥
            if image is not None:
                # å¤„ç†å›¾ç‰‡
                image_np = image[0].cpu().numpy()
                image_np = (image_np * 255).astype(np.uint8)
                image_pil = Image.fromarray(image_np)
                
                # è½¬æ¢ä¸ºbase64
                with BytesIO() as output:
                    image_pil.save(output, format="PNG")
                    image_bytes = output.getvalue()
                base64_image = base64.b64encode(image_bytes).decode("utf-8")
                image_url = f"data:image/png;base64,{base64_image}"
                
                # ä½¿ç”¨å›¾åƒæ¨¡å¼
                completion = self.create_image_completion(
                    client, system_prompt, user_prompt, image_url,
                    max_tokens=max_tokens
                )
            else:
                # ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼
                completion = self.create_text_completion(
                    client, system_prompt, user_prompt,
                    max_tokens=max_tokens
                )

            # è·å–å“åº”å¹¶è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            response_dict = json.loads(completion.model_dump_json())
            
            # å¤„ç†å“åº”
            processed_response = self.post_process_prompt(response_dict)
            return (processed_response,)
                
        except Exception as e:
            return (f"Error: {str(e)}",)

NODE_CLASS_MAPPINGS = {
    "ImageCaptioner": ImageCaptioner
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageCaptioner": "AI Chat & Image Captioner"
}

